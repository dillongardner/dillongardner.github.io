---
title: "STL_Part_II"
author: "Dillon Gardner"
date: "November 22, 2016"
output: html_document
---

This part of a three part series on STL decomposition focuses on a sketch of the algorithm. It is not a rigorous treatment, but hopefully thorough enough to provide a mathematical understanding of how the various hyperparameters affect the decomposition. This post is a bit heavy on the mathematics. For an introduction to STL, please look at Part I

STL (Seasonal Trend decomposition using Loess) was developed by Cleveland et al. [(Journal of Official Statistics 6 No. 1 pp 3-33 1990)] (http://www.wessa.net/download/stl.pdf). The core idea is that a time series can be decomposed into three components: seasonal, trend and remainder ($Y_\nu = T_\nu + S_\nu + R_\nu$) for $\nu = 1$ to $N$ measured data points. The algorithmic details is not commonly discussed in time series texts in part because unlike other methods, there is no notion of a loss function to be minimized. This is because the notional of seasonal variation is always intrinsically ambiguous: whether the temporal variation should be considered Seasonal, Trend, or Remainder is, to a degree, a matter of opinion and determined by choice of model and model parameters. This is true in STL as well as any seasonal variational approach.

Key to the STL approach is Loess (LOcal regrESSion) smoothing. For a set of measurements $y_i$, and $x_i$, Loess provides smooth estimate $g(x)$ for $y$ at all values of $x$, not just at values $x_i$ for which $y$ has been measured. To calculate $g$, a positive integer $q$ is chosen. A larger $q$, yields greater smoothing. The $q$ values of $x_i$ that are closes to $x$ are selected and each is weighted by how far it is from $x$. The weight is determined as $v_i = W(|x_i−x|$) where $W$ is the tricube weight function and $\lambda_q (x)$ is the distance from the $q^{th}$ farthest point (for $q < N$. If $q >= N$, additional scale terms must be used). A polynomial of degree $d$ (typically one or two) is fit to the selected $(x_i,y_i)$ with weights $v_i$. In addition, it is possible to have a set of robustness weights $\rho_i$ for each data point $(x_i, y_i)$. These weights allow for some data points to be considered more heavily in the regression. If robustness weights exist, use weights $\rho_i v_i$. For STL, selection of smoothing parameters $q$ and to a lesser extent $d$ are a key model choice.

Model parameters

* $n_{(p)}$ = number of observations in each cycle of the seasonal component
* $n_{(i)}$ = number of cycles through the inner loop. Number of cycles should be large enough to reach convergence. When multiple outer cycles, the number of inner cycles can be smaller as they do not necessarily help get overall convergence
* $n_{(o)}$ = number of cycles through the outer loop. More cycles here reduce the affect of outliers
* $n_{(l)}$ = the span in lags for the low-pass filter. Almost always taken as the least odd integer greater
than or eqaul to $n(p)$
* $n_{(s)}$ = smoothing parameter for the seasonal filter. As ns increases, each cycle subseries becomes
smoother. This is one of the parameters with the most freedom of choice from the modeler. It looks like it can become a question of what the modeler believes is changes in seasonal behavior versus aberrant behavior.
* $n_{(t)}$ = smoothing parameter of the trend behavior. As this increases, the trend is increasingly smoothed. The authors recommend “consider [the trend] to be a component whose estimation is needed to form an estimate of the seasonal.” If more careful trend modeling is needed, they recommend first extracting the seasonal, then model the sum of $T_\nu + R_\nu$.

In addition to these six paramters, the degree of the loess smoothing can be changed. The default is typically $d$ = 1 for all the smoothing. There are more paramters in the R STL function, which are related to the computation parameters and (I believe) do not affect the resulting model.


## Algorithmic sketch

The goal is to separate a time series $Y_\nu$ for $\nu = 1$ to $N$ into $Y_\nu = T_\nu + S_\nu + R_\nu$, trend, seasonal and remainder components. This is done through two loops. In the outer loop, robustness weights are assigned to each data point depending on the size of the remainder. The inner loop interatively updates the trend and seasonal components. This is done by subtracting the current estimate of the trend from the raw series. The time series is then partition into cycle-subseries (e.g. if it is monthly data with a yearly season, then there will be 12 cycle subseries: all Januarys will be one TS, all February a second, etc.). The cycle-subseries are loess smoothed and then passed thorugh a low-pass filter. The seasonal components are the smoothed cycle-subseries minus the result from the low-pass filter. The seasonal components are subtracted from the raw data. The result is loess smoothed, which becomes the trend. What is left is the remainder. In the outline below, the notation follows the Cleveland paper.

1. Initialize trend as $T_\nu^{(0)} = 0$ and $R_\nu^{(0)}=0$
2. Outer loop - Calculate robustness weights. Run $n_{(o)}$ times
  + Calculate Rν
  + Calculate robustness weights $\rho_\nu = B(|R_\nu|/h)$ where $h = 6 ∗ median(|R_\nu|)$ and $B$ is the bisquare weight function [1]
  + On initial loop, $\rho_\nu$ = 1 
3. Inner loop - Iteratively calculate trend and seasonal terms. Run $n_{(i)}$ times
  + Detrend: $Y_\nu − T_\nu^{(k)}$ where $k$ is the loop number. If the observed value $Y_\nu$ is missing, then the detrended term is also missing
  + Cycle-subseries smoothing: The detrended time series is broken into cycle-subseries. For example, monthly data with a periodicity of twelve months would yield twelve cycle-subseries, one of which would be all of the months of January. Each cycle-subseries is then loess smoothed with $q = n_(s)$ and $d=1$. In stl package in R, $n_(s)$ can accept the keyword “periodic” instead. The package notes say this makes smoothing “effectively replaced by taking the mean.” The smoothed values yield a temporary seasonal time series $C^{k+1}$.
  + Low-pass filter: The low pass filter on $C^{k+1}$ yields $L^{k+1}$. This filter is the application of two moving averages of lag equal to three followed by loess filtering with $q = n_{(l)}$ and $d=1$. $n_{(l)}$ is defaulted the smallest odd integer greater than the period (e.g. 13 for monthly data). The output of the low-pass filter is $L^{k+1}$
  + Detrending of smoothed cycle-subseries: $S^{k+1} = C^{k+1} − L^{k+1}$. This is the $k+1$th estimate of seasonal component.
  + Deseasonalizing: $Y − S^{k+1}$
  + Trend smoothing: Loess smooth the deseasonalized time series with $q=n_{(t)}$. Results in $T^{k+1}$, the k+1$th estimate of the trend component
  

[1] $B(u) = (1 - u^2)^2$ for $0 \le u \le 1$ $B(u) = 0$ for all other $u$ 
